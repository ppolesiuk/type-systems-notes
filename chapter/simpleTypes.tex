\chapter{Simple Types}
\label{ch:simple-types}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Simply Typed Lambda Calculus}

\newcommand\CaseTerm[3]{\texttt{case}\;#1\;\texttt{of}\;\iota_1\;x.#2\texttt{|}\iota_2\;x.#3}
\newcommand\iotaval{\iota^{\textsc{v}}}

As pure lambda calculus has empty grammar of types, we need to extend it with
some atomic values $c_b$ of type $b$, which can for example be numbers or booleans.

\begin{alignat*}{2}
  \syncatset{Type} & \ni \tau && \Coloneqq \tau \to \tau \mid b
    \tag{types} \\
  \syncatset{Expr} & \ni e && \Coloneqq v \mid e\;e
    \tag{expressions} \\
  \syncatset{Val} & \ni v && \Coloneqq x \mid \lambda x.e \mid c_b
    \tag{values}
\end{alignat*}

To derive a type of lambda abstraction, we need to first derive it for its body, remembering that current variable is bound to some type.
As lambda terms can be nested, we must store somewhere a set of assumptions about free variables occurring in a term.
This place is called environment $\Gamma$. \\

$\Gamma\vdash e : \tau$ - In context $\Gamma$ expression $e$ has type $\tau$

$\Gamma ::= \emptyset \mid \Gamma, x : \tau$

$(x:\tau) \Leftrightarrow \Gamma(x) = \tau$

$\Gamma, x:\tau \Leftrightarrow \Gamma[x \mapsto \tau]$

\begin{mathpar}
  \inferrule{ }
            {\Gamma\vdash c_b : b}

  \inferrule{(x : \tau) \in \Gamma}
            {\Gamma\vdash x : \tau}
    
  \inferrule{\Gamma, x : \tau_1 \vdash e : \tau_2}
            {\Gamma\vdash \lambda x.e : \tau_1 \to \tau_2}
  
  \inferrule{\Gamma\vdash e_1 : \tau_2 \to \tau_1 \\ \Gamma\vdash e_2 : \tau_2}
            {\Gamma\vdash e_1\;e_2 : \tau_1}
\end{mathpar}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Curry--Howard Isomorphism and Some New Constructs}

Now, let's remove all terms from typing rules above and squint our eyes a little. 
What do we see? A wild natural deduction appears!

\begin{mathpar}
  \inferrule{\tau \in \Gamma}
            {\Gamma\vdash \tau}

  \inferrule{\Gamma, \tau_1 \vdash \tau_2}
            {\Gamma\vdash \tau_1 \to \tau_2}
  
  \inferrule{\Gamma\vdash \tau_2 \to \tau_1 \\ \Gamma\vdash \tau_2}
            {\Gamma\vdash \tau_1}

\end{mathpar}
Notice that the structure of a term mirrors its type derivation---whenever 
we see a lambda-abstraction, we know that an implication was introduced; 
whenever we see an application, we know that an implication was eliminated.

The version of natural deduction that we know from the Logic course also contains 
rules for other connectives. For instance, we can introduce $\top$ and eliminate $\bot$. 

\begin{mathpar}
\inferrule{ }{\Gamma \vdash \top}

\inferrule{\Gamma \vdash \bot}
	    {\Gamma \vdash \tau}
\end{mathpar}

Let us try to add top and bottom types to our calculus. The introduction rule 
of $\top$ means that one can always assert that $\top$ is true. Now, we want 
to be always able to assert that \textit{something} has type $\top$. 
This \textit{something} is going to be the \textit{unit} $\langle \rangle$---a 
new value in the grammar of values. What about $\bot$? Having an expression 
of type $\bot$, we should be able to construct an expression of an arbitrary type. 
But what does an expression of type $\bot$ represent? Well, its type derivation 
must be a proof of a contradiction. We know from experience that reaching 
a contradiction may be useful for some greater goal. Once we have proven 
a contradiction, we usually point it out, saying, ``this is a contradiction''.  
For this purpose, we add the \texttt{absurd} syntactical construct to the grammar 
of expressions. No reduction rules for it will be provided.

\begin{mathpar}
\inferrule{ }{\Gamma \vdash \langle \rangle : \top}

\inferrule{\Gamma \vdash e : \bot}
	    {\Gamma \vdash \texttt{absurd}\ e : \tau}
\end{mathpar}

Now consider negation. The introduction of $\neg \tau$ is identical to 
the introduction of $\tau \rightarrow \bot$. Moreover, the elimination 
of negation states that from $\tau$ and $\neg \tau$ we can get $\bot$, 
and indeed we obtain $\bot$ from $\tau$ and $\tau \rightarrow \bot$ 
by elimination of implication. Therefore we need not worry about negation 
and may proceed to conjunction and disjunction, for which we have 
the following inference rules.

\begin{mathpar}
  \inferrule{\Gamma\vdash \tau_1 \\ \Gamma\vdash \tau_2}
            {\Gamma\vdash \tau_1 \land \tau_2}

  \inferrule{\Gamma\vdash \tau_1 \land \tau_2}
            {\Gamma\vdash \tau_i} \text{ for } i \in \{1, 2\}
\\\\
  \inferrule{\Gamma\vdash \tau_i}
            {\Gamma\vdash \tau_1 \lor \tau_2} \text{ for } i \in \{1, 2\}

  \inferrule{\Gamma\vdash \tau_1 \lor \tau_2 \\ \Gamma, \tau_1 \vdash \tau \\ \Gamma, \tau_2 \vdash \tau}
            {\Gamma\vdash \tau}
\end{mathpar}

A term of type $\tau_1 \land \tau_2$ should be a proof that there exists a term 
of type $\tau_1$ and that there exists a term of type $\tau_2$. The best proof 
of this is, of course, a pair of such terms. Just like we eliminate a conjunction 
by choosing one of its conjuncts, we deconstruct a pair by choosing one 
of its components. This time, we will go away from the notational conventions 
of propositional calculus and use the symbol $\times$ instead of $\land$ 
(this makes sense because a conjunction is a ``logical product'').

\begin{mathpar}
\inferrule{\Gamma\vdash e_1 : \tau_1 \\ \Gamma\vdash e_2 : \tau_2}
          {\Gamma\vdash (e_1, e_2) : \tau_1\times\tau_2}

\inferrule{\Gamma\vdash e : \tau_1\times\tau_2}
          {\Gamma\vdash \pi_i\;e : \tau_i} \text{ for } i \in \{1, 2\}
\\\\
\inferrule{ }{\pi_i\;\langle v_1, v_2 \rangle \rightharpoonup v_i} \text{ for } i \in \{1, 2\} 
\end{mathpar}

As for disjunction, a term of type $\tau_1 \lor \tau_2$ should contain either 
a $\tau_1$-term or a $\tau_2$-term. This is known as a union type. We use 
the constructors $\iota_1, \iota_2$ to mark which case we are dealing with. 
In order to eliminate $\tau_1 \lor \tau_2$, we analyze two cases. 
Each variant must suffice to obtain some $\tau$-term. We write + instead of $\lor$ 
(a disjunction is a ``logical sum''). 

\begin{mathpar}
\inferrule{\Gamma\vdash e : \tau_i}
            {\Gamma\vdash \iota_i\;e : \tau_1+\tau_2} \text{ for } i \in \{1, 2\}
\\\\
  \inferrule{\Gamma\vdash e : \tau_1+\tau_2 \\ \Gamma, x : \tau_i \vdash e_i : \tau \text{ for } i\in \{1, 2\}}
            {\Gamma\vdash \CaseTerm{e}{e_1}{e_2} : \tau}
\\\\
\inferrule{ }{\iota_i\;v \rightharpoonup \iotaval_i\;v} \text{ for } i \in \{1, 2\} 
  
\inferrule{ }{\CaseTerm{\iotaval_i\;v}{e_1}{e_2} \rightharpoonup e_i\{v/x\}}
\end{mathpar}

For hygiene's sake, we distinguish $\langle v, v \rangle$, the value, 
from $(e, e)$, the expression. Similarly, we distinguish $\iotaval_i v$ 
from $\iota_i e$. Formally, it may be a good idea to add separate typing rules 
for these value-constructs. Expression-constructs reduce to their corresponding 
value-constructs according to the following rules.

\begin{mathpar}
\inferrule{ }{(v_1, v_2) \rightharpoonup \langle v_1, v_2 \rangle}

\inferrule{ }{\iota_i\;v \rightharpoonup \iotaval_i\;v} \text{ for } i \in \{1, 2\} 
\end{mathpar}

Finally, let us look at the resulting grammar of types, expressions, values and evaluation contexts.

\begin{alignat*}{2}
  \tau & \Coloneqq \ldots \mid \top \mid \bot \mid \tau\times\tau \mid \tau+\tau \\
  e & \Coloneqq \ldots \mid \texttt{absurd}\ e \mid (e,e)
      \mid \pi_1\;e \mid \pi_2\;e
      \mid \iota_1\;e \mid \iota_2\;e \mid \CaseTerm{e}{e}{e}
    \\
  v & \Coloneqq \ldots \mid \langle \rangle \mid \langle v, v \rangle
    \mid \iotaval_1\;v \mid \iotaval_2\;v
    \\
E & \Coloneqq \ldots \mid (E,e) \mid (v,E)
    \mid \pi_1\;E \mid \pi_2\;E
    \mid \iota_1\;E \mid \iota_2\;E 
    \mid \CaseTerm{E}{e_1}{e_2}
\end{alignat*}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Progress and Preservation}

\begin{defin}[Type safety]
  We say that expression $e$ is \emph{type-safe}, written $\Safe{e}$
  if for any expressions $e'$ such that $e \longrightarrow^* e'$
  expression $e'$ is a value, or it makes a step, \emph{i.e.},
  there exists $e''$ such that $e' \longrightarrow e''$.
\end{defin}

20th century technique: progress + type preservation

\begin{theorem}[Progress]
  If $\emptyset\vdash e : \tau$ then
  $e$ is a value or there exists expression~$e'$
  such that $e \longrightarrow e'$.
\end{theorem}
\begin{proof}
  Induction on the derivation of $\emptyset\vdash e : \tau$.
  Cases for unit value, variable, and lambda abstraction are trivial ---
  they are already values.
  For application case ($e_1\;e_2$), by induction hypothesis we have one
  of the following subcases: either $e_1$ makes a step,
  $e_1$ is a value and $e_2$ makes a step,
  or both $e_1$ and $e_2$ are values, $v_1$ and $v_2$ correspondingly.
  In the first two subcases the whole application makes a step.
  For the last one, we need to ensure that $v_1$ is a lambda abstraction.
  While in case of simple types this directly follows from the typing rules,
  we state this property as a separate inversion lemma (below).
\end{proof}

\begin{lemma}[Inversion for arrow type]
  If $\emptyset\vdash v : \tau_1 \to \tau_2$
  then $v = \lambda x.e$ for some $x$ and $e$,
  such that $x:\tau_1 \vdash e : \tau_2$.
\end{lemma}
\begin{proof}
  Directly by the definition of a typing relation.
  Note that the assumption about the emptiness of the typing environment
  is crucial, since variables may have an arrow type.
\end{proof}

We have defined an inversion lemma as a separate lemma in order
to make this proof technique more robust.
In case of some language extensions, like subtyping,
this lemma is not so trivial and require some additional reasoning.

\begin{theorem}
  Typing relation is preserved by a reduction.
  More precisely, if $\emptyset \vdash e : \tau$ and $e \longrightarrow e'$ then
  $\emptyset \vdash e' : \tau$.
\end{theorem}
\begin{proof}
  By induction on the typing derivation.
  Details are left as an exercise for the reader.
  In case of reductions that uses substitution ($\beta$-reduction)
  we need a substitution lemma, which in turn requires weakening lemmas.
  Both lemmas are stated below.
\end{proof}

\begin{lemma}[Weakening]
  If $\Gamma\vdash e : \tau$ then $\Gamma, x:\tau' \vdash e : \tau$
  for $x\not\in \textsf{dom}(\Gamma)$.
\end{lemma}
\begin{proof}
  By induction on the typing derivation.
  Details are left as an exercise for the reader.
\end{proof}

\begin{lemma}[Substitution]
  If $\Gamma, x:\tau_1 \vdash e : \tau_2$ and $\Gamma\vdash v : \tau_1$
  then $\Gamma\vdash e\{v/x\} : \tau_2$
\end{lemma}
\begin{proof}
  By induction on the typing derivation.
  Details are left as an exercise for the reader.
\end{proof}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Further Reading}
